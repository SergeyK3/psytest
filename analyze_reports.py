"""
–ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö AI –æ—Ç—á—ë—Ç–æ–≤
–°—Ä–∞–≤–Ω–∏–≤–∞–µ—Ç —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –æ—Ç—á—ë—Ç–æ–≤ —Å –æ–∂–∏–¥–∞–Ω–∏—è–º–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø—Ä–æ—Ñ–∏–ª—è
"""

import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ src –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
sys.path.insert(0, str(Path(__file__).parent / "src"))

from test_scenarios import TEST_SCENARIOS

def analyze_report_quality():
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –∫–∞—á–µ—Å—Ç–≤–æ –≤—Å–µ—Ö —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤"""
    
    reports_dir = Path(__file__).parent / "test_reports"
    
    print("üìä –ê–Ω–∞–ª–∏–∑ –∫–∞—á–µ—Å—Ç–≤–∞ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –æ—Ç—á—ë—Ç–æ–≤")
    print("=" * 60)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–π —Å—Ü–µ–Ω–∞—Ä–∏–π
    for scenario_name, scenario_data in TEST_SCENARIOS.items():
        report_path = reports_dir / f"report_{scenario_name}.txt"
        
        if not report_path.exists():
            print(f"‚ùå –û—Ç—á—ë—Ç –¥–ª—è {scenario_name} –Ω–µ –Ω–∞–π–¥–µ–Ω")
            continue
            
        print(f"\nüîç –ê–Ω–∞–ª–∏–∑: {scenario_data['name']}")
        print(f"üìù –û–ø–∏—Å–∞–Ω–∏–µ: {scenario_data['description']}")
        
        # –ß–∏—Ç–∞–µ–º –æ—Ç—á—ë—Ç
        with open(report_path, 'r', encoding='utf-8') as f:
            report_content = f.read()
        
        # –ê–Ω–∞–ª–∏–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –æ—Ç—á—ë—Ç–∞
        analyze_report_structure(report_content, scenario_data)
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏—è –ø—Ä–æ—Ñ–∏–ª—é
        analyze_profile_match(report_content, scenario_data)

def analyze_report_structure(content: str, scenario_data: dict):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å—Ç—Ä—É–∫—Ç—É—Ä—É –æ—Ç—á—ë—Ç–∞"""
    
    required_sections = [
        "–û–±—â–∏–µ –¥–∞–Ω–Ω—ã–µ –æ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–µ",
        "–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ –ê–¥–∏–∑–µ—Å—É",
        "–¢–ï–°–¢ DISC",
        "–¢–ï–°–¢ HEXACO",
        "Powered by OpenAI"
    ]
    
    missing_sections = []
    for section in required_sections:
        if section not in content:
            missing_sections.append(section)
    
    if missing_sections:
        print(f"  ‚ö†Ô∏è  –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ —Ä–∞–∑–¥–µ–ª—ã: {', '.join(missing_sections)}")
    else:
        print("  ‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –æ—Ç—á—ë—Ç–∞ –ø–æ–ª–Ω–∞—è")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–ª–∏–Ω—É –æ—Ç—á—ë—Ç–∞
    word_count = len(content.split())
    if word_count < 200:
        print(f"  ‚ö†Ô∏è  –û—Ç—á—ë—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π: {word_count} —Å–ª–æ–≤")
    elif word_count > 1000:
        print(f"  ‚ö†Ô∏è  –û—Ç—á—ë—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π: {word_count} —Å–ª–æ–≤")
    else:
        print(f"  ‚úÖ –û–±—ä—ë–º –æ—Ç—á—ë—Ç–∞ –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π: {word_count} —Å–ª–æ–≤")

def analyze_profile_match(content: str, scenario_data: dict):
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –æ—Ç—á—ë—Ç–∞ –ø—Ä–æ—Ñ–∏–ª—é –ª–∏—á–Ω–æ—Å—Ç–∏"""
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ –ø—Ä–æ—Ñ–∏–ª–µ–π
    profile_keywords = {
        "manager_leader": ["–ª–∏–¥–µ—Ä", "—Ä—É–∫–æ–≤–æ–¥–∏—Ç–µ–ª—å", "–æ—Ç–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ—Å—Ç—å", "—Ä–µ–∑—É–ª—å—Ç–∞—Ç", "–∫–æ–Ω—Ç—Ä–æ–ª—å"],
        "creative_innovator": ["—Ç–≤–æ—Ä—á–µ—Å—Ç", "–∫—Ä–µ–∞—Ç–∏–≤", "–∏–Ω–Ω–æ–≤–∞", "–∏–¥–µ–∏", "–Ω–æ–≤–æ–µ"],
        "stable_supporter": ["—Å—Ç–∞–±–∏–ª—å", "–ø–æ—Ä—è–¥–æ–∫", "–ø—Ä–∞–≤–∏–ª–∞", "—Å–∏—Å—Ç–µ–º–Ω", "–Ω–∞–¥—ë–∂–Ω"],
        "team_integrator": ["–∫–æ–º–∞–Ω–¥", "–∏–Ω—Ç–µ–≥—Ä–∞—Ü", "—Å–æ—Ç—Ä—É–¥–Ω–∏—á–µ—Å—Ç", "—ç–º–ø–∞—Ç–∏", "–≥–∞—Ä–º–æ–Ω–∏"],
        "analytical_perfectionist": ["–∞–Ω–∞–ª–∏–∑", "–¥–µ—Ç–∞–ª–∏", "—Ç–æ—á–Ω–æ—Å—Ç", "–∫–∞—á–µ—Å—Ç–≤–æ", "—Å—Ç–∞–Ω–¥–∞—Ä—Ç"],
        "balanced_universal": ["—Å–±–∞–ª–∞–Ω—Å", "—É–Ω–∏–≤–µ—Ä—Å–∞–ª", "–∞–¥–∞–ø—Ç–∞—Ü", "–≥–∏–±–∫–æ—Å", "—Ä–∞–∑–Ω–æ—Å—Ç–æ—Ä–æ–Ω"]
    }
    
    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø—Ä–æ—Ñ–∏–ª—è
    profile_type = None
    for scenario_name, _ in TEST_SCENARIOS.items():
        if scenario_name in content or any(keyword in scenario_data['name'].lower() for keyword in scenario_name.split('_')):
            profile_type = scenario_name
            break
    
    if not profile_type:
        # –ü—ã—Ç–∞–µ–º—Å—è –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞/—Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É
        for scenario_name in TEST_SCENARIOS.keys():
            if scenario_name in str(content).lower():
                profile_type = scenario_name
                break
    
    if profile_type and profile_type in profile_keywords:
        keywords = profile_keywords[profile_type]
        found_keywords = []
        
        content_lower = content.lower()
        for keyword in keywords:
            if keyword in content_lower:
                found_keywords.append(keyword)
        
        keyword_score = len(found_keywords) / len(keywords) * 100
        
        if keyword_score >= 60:
            print(f"  ‚úÖ –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ—Ñ–∏–ª—é: {keyword_score:.1f}% (–Ω–∞–π–¥–µ–Ω—ã –∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {', '.join(found_keywords)})")
        elif keyword_score >= 30:
            print(f"  ‚ö†Ô∏è  –ß–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ—Ñ–∏–ª—é: {keyword_score:.1f}%")
        else:
            print(f"  ‚ùå –°–ª–∞–±–æ–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø—Ä–æ—Ñ–∏–ª—é: {keyword_score:.1f}%")
    else:
        print("  ‚ö†Ô∏è  –ù–µ —É–¥–∞–ª–æ—Å—å –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å —Ç–∏–ø –ø—Ä–æ—Ñ–∏–ª—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")

def generate_summary_report():
    """–ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á—ë—Ç –ø–æ –≤—Å–µ–º –ø—Ä–æ—Ñ–∏–ª—è–º"""
    
    reports_dir = Path(__file__).parent / "test_reports"
    
    print("\n" + "=" * 60)
    print("üìã –°–í–û–î–ö–ê –ü–û –í–°–ï–ú –ü–†–û–§–ò–õ–Ø–ú")
    print("=" * 60)
    
    total_reports = len(TEST_SCENARIOS)
    existing_reports = len(list(reports_dir.glob("*.txt")))
    
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"  ‚Ä¢ –í—Å–µ–≥–æ –ø—Ä–æ—Ñ–∏–ª–µ–π: {total_reports}")
    print(f"  ‚Ä¢ –°–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–æ –æ—Ç—á—ë—Ç–æ–≤: {existing_reports}")
    print(f"  ‚Ä¢ –ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è: {existing_reports/total_reports*100:.1f}%")
    
    print(f"\nüéØ –¢–∏–ø—ã –ø—Ä–æ—Ñ–∏–ª–µ–π:")
    for scenario_name, scenario_data in TEST_SCENARIOS.items():
        status = "‚úÖ" if (reports_dir / f"report_{scenario_name}.txt").exists() else "‚ùå"
        print(f"  {status} {scenario_data['name']} - {scenario_data['description']}")
    
    print(f"\nüí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:")
    print("  ‚Ä¢ –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏–π –ø—Ä–æ—Ñ–∏–ª—è–º –ª–∏—á–Ω–æ—Å—Ç–∏")
    print("  ‚Ä¢ –£–±–µ–¥–∏—Ç–µ—Å—å –≤ –Ω–∞–ª–∏—á–∏–∏ –≤—Å–µ—Ö –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö —Ä–∞–∑–¥–µ–ª–æ–≤")
    print("  ‚Ä¢ –°—Ä–∞–≤–Ω–∏—Ç–µ —Å –ø—Ä–∏–º–µ—Ä–æ–º '–ü—Å–∏—Ö–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–π –ø–æ—Ä—Ç—Ä–µ—Ç –ö–∏–º–°–í.docx'")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∞–Ω–∞–ª–∏–∑–∞"""
    analyze_report_quality()
    generate_summary_report()

if __name__ == "__main__":
    main()